usage: main.py [-h] [--name NAME]
               [--mode {train-discriminator,train-generator,eval-discriminator,eval-generator,batch-eval}]
               [--epochs EPOCHS] [--gpu GPU] [--perceptual-loss]
               [--vgg-perceptual-loss] [--lr LR] [--in INFILE] [--out OUTFILE]

Train and/or evaluate WMn --> CSFn model.

optional arguments:
  -h, --help            show this help message and exit
  --name NAME           Model name to save/load (default: model)
  --mode {train-discriminator,train-generator,eval-discriminator,eval-generator,batch-eval}
  --epochs EPOCHS       Epochs to train for, if training (default: 10)
  --gpu GPU             Passed to CUDA_VISIBLE_DEVICES (default: None)
  --perceptual-loss     Custom perceptual loss for training (default: False)
  --vgg-perceptual-loss
                        VGG16-based perceptual loss for training (default:
                        False)
  --lr LR               Adam learning rate (default: 0.001)
  --in INFILE           Volume to load for generator evaluation (default:
                        None)
  --out OUTFILE         Output save path for generator evaluation (default:
                        None)

discriminator:
  python3 main.py --name discriminator --mode train-discriminator --epochs 50

single_slice:
  python3 main.py --name single_slice --mode train-generator --epochs 50

single_slice_vgg:
  python3 main.py --name single_slice --mode train-generator --epochs 50 --vgg-perceptual-loss

single_slice_perceptual:
  python3 main.py --name single_slice_perceptual --mode train-generator --epochs 50 --perceptual-loss
